import itertools
import numpy as np
from _typeshed import Incomplete
from collections.abc import Hashable, Iterator
from pandas import DataFrame as DataFrame, DatetimeIndex as DatetimeIndex, Index as Index, MultiIndex as MultiIndex, PeriodIndex as PeriodIndex, RangeIndex as RangeIndex, Series as Series, TimedeltaIndex as TimedeltaIndex, concat as concat, isna as isna
from pandas._config import config as config, get_option as get_option, using_copy_on_write as using_copy_on_write, using_pyarrow_string_dtype as using_pyarrow_string_dtype
from pandas._libs import lib as lib
from pandas._libs.lib import is_string_array as is_string_array
from pandas._libs.tslibs import timezones as timezones
from pandas._typing import AnyArrayLike as AnyArrayLike, ArrayLike as ArrayLike, AxisInt as AxisInt, DtypeArg as DtypeArg, FilePath as FilePath, Self as Self, Shape as Shape, npt as npt
from pandas.compat._optional import import_optional_dependency as import_optional_dependency
from pandas.compat.pickle_compat import patch_pickle as patch_pickle
from pandas.core.arrays import Categorical as Categorical, DatetimeArray as DatetimeArray, PeriodArray as PeriodArray
from pandas.core.computation.pytables import PyTablesExpr as PyTablesExpr, maybe_expression as maybe_expression
from pandas.core.construction import extract_array as extract_array
from pandas.core.dtypes.common import ensure_object as ensure_object, is_bool_dtype as is_bool_dtype, is_complex_dtype as is_complex_dtype, is_list_like as is_list_like, is_string_dtype as is_string_dtype, needs_i8_conversion as needs_i8_conversion
from pandas.core.dtypes.dtypes import CategoricalDtype as CategoricalDtype, DatetimeTZDtype as DatetimeTZDtype, ExtensionDtype as ExtensionDtype, PeriodDtype as PeriodDtype
from pandas.core.dtypes.missing import array_equivalent as array_equivalent
from pandas.core.indexes.api import ensure_index as ensure_index
from pandas.core.internals import ArrayManager as ArrayManager, Block as Block, BlockManager as BlockManager
from pandas.errors import AttributeConflictWarning as AttributeConflictWarning, ClosedFileError as ClosedFileError, IncompatibilityWarning as IncompatibilityWarning, PerformanceWarning as PerformanceWarning, PossibleDataLossError as PossibleDataLossError
from pandas.io.common import stringify_path as stringify_path
from pandas.io.formats.printing import adjoin as adjoin, pprint_thing as pprint_thing
from pandas.util._decorators import cache_readonly as cache_readonly
from pandas.util._exceptions import find_stack_level as find_stack_level
from tables import Col as Col, File as File, Node as Node
from types import TracebackType
from typing import Any, Final, Literal

Term = PyTablesExpr
incompatibility_doc: Final[str]
attribute_conflict_doc: Final[str]
performance_doc: Final[str]
dropna_doc: Final[str]
format_doc: Final[str]

def to_hdf(path_or_buf: FilePath | HDFStore, key: str, value: DataFrame | Series, mode: str = 'a', complevel: int | None = None, complib: str | None = None, append: bool = False, format: str | None = None, index: bool = True, min_itemsize: int | dict[str, int] | None = None, nan_rep: Incomplete | None = None, dropna: bool | None = None, data_columns: Literal[True] | list[str] | None = None, errors: str = 'strict', encoding: str = 'UTF-8') -> None: ...
def read_hdf(path_or_buf: FilePath | HDFStore, key: Incomplete | None = None, mode: str = 'r', errors: str = 'strict', where: str | list | None = None, start: int | None = None, stop: int | None = None, columns: list[str] | None = None, iterator: bool = False, chunksize: int | None = None, **kwargs): ...

class HDFStore:
    def __init__(self, path, mode: str = 'a', complevel: int | None = None, complib: Incomplete | None = None, fletcher32: bool = False, **kwargs) -> None: ...
    def __fspath__(self) -> str: ...
    @property
    def root(self): ...
    @property
    def filename(self) -> str: ...
    def __getitem__(self, key: str): ...
    def __setitem__(self, key: str, value) -> None: ...
    def __delitem__(self, key: str) -> None: ...
    def __getattr__(self, name: str): ...
    def __contains__(self, key: str) -> bool: ...
    def __len__(self) -> int: ...
    def __enter__(self) -> Self: ...
    def __exit__(self, exc_type: type[BaseException] | None, exc_value: BaseException | None, traceback: TracebackType | None) -> None: ...
    def keys(self, include: str = 'pandas') -> list[str]: ...
    def __iter__(self) -> Iterator[str]: ...
    def items(self) -> Iterator[tuple[str, list]]: ...
    def open(self, mode: str = 'a', **kwargs) -> None: ...
    def close(self) -> None: ...
    @property
    def is_open(self) -> bool: ...
    def flush(self, fsync: bool = False) -> None: ...
    def get(self, key: str): ...
    def select(self, key: str, where: Incomplete | None = None, start: Incomplete | None = None, stop: Incomplete | None = None, columns: Incomplete | None = None, iterator: bool = False, chunksize: int | None = None, auto_close: bool = False): ...
    def select_as_coordinates(self, key: str, where: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...
    def select_column(self, key: str, column: str, start: int | None = None, stop: int | None = None): ...
    def select_as_multiple(self, keys, where: Incomplete | None = None, selector: Incomplete | None = None, columns: Incomplete | None = None, start: Incomplete | None = None, stop: Incomplete | None = None, iterator: bool = False, chunksize: int | None = None, auto_close: bool = False): ...
    def put(self, key: str, value: DataFrame | Series, format: Incomplete | None = None, index: bool = True, append: bool = False, complib: Incomplete | None = None, complevel: int | None = None, min_itemsize: int | dict[str, int] | None = None, nan_rep: Incomplete | None = None, data_columns: Literal[True] | list[str] | None = None, encoding: Incomplete | None = None, errors: str = 'strict', track_times: bool = True, dropna: bool = False) -> None: ...
    def remove(self, key: str, where: Incomplete | None = None, start: Incomplete | None = None, stop: Incomplete | None = None) -> None: ...
    def append(self, key: str, value: DataFrame | Series, format: Incomplete | None = None, axes: Incomplete | None = None, index: bool | list[str] = True, append: bool = True, complib: Incomplete | None = None, complevel: int | None = None, columns: Incomplete | None = None, min_itemsize: int | dict[str, int] | None = None, nan_rep: Incomplete | None = None, chunksize: int | None = None, expectedrows: Incomplete | None = None, dropna: bool | None = None, data_columns: Literal[True] | list[str] | None = None, encoding: Incomplete | None = None, errors: str = 'strict') -> None: ...
    def append_to_multiple(self, d: dict, value, selector, data_columns: Incomplete | None = None, axes: Incomplete | None = None, dropna: bool = False, **kwargs) -> None: ...
    def create_table_index(self, key: str, columns: Incomplete | None = None, optlevel: int | None = None, kind: str | None = None) -> None: ...
    def groups(self) -> list: ...
    def walk(self, where: str = '/') -> Iterator[tuple[str, list[str], list[str]]]: ...
    def get_node(self, key: str) -> Node | None: ...
    def get_storer(self, key: str) -> GenericFixed | Table: ...
    def copy(self, file, mode: str = 'w', propindexes: bool = True, keys: Incomplete | None = None, complib: Incomplete | None = None, complevel: int | None = None, fletcher32: bool = False, overwrite: bool = True) -> HDFStore: ...
    def info(self) -> str: ...

class TableIterator:
    chunksize: int | None
    store: HDFStore
    s: GenericFixed | Table
    func: Incomplete
    where: Incomplete
    nrows: Incomplete
    start: Incomplete
    stop: Incomplete
    coordinates: Incomplete
    auto_close: Incomplete
    def __init__(self, store: HDFStore, s: GenericFixed | Table, func, where, nrows, start: Incomplete | None = None, stop: Incomplete | None = None, iterator: bool = False, chunksize: int | None = None, auto_close: bool = False) -> None: ...
    def __iter__(self) -> Iterator: ...
    def close(self) -> None: ...
    def get_result(self, coordinates: bool = False): ...

class IndexCol:
    is_an_indexable: bool
    is_data_indexable: bool
    values: Incomplete
    kind: Incomplete
    typ: Incomplete
    name: Incomplete
    cname: Incomplete
    axis: Incomplete
    pos: Incomplete
    freq: Incomplete
    tz: Incomplete
    index_name: Incomplete
    ordered: Incomplete
    table: Incomplete
    meta: Incomplete
    metadata: Incomplete
    def __init__(self, name: str, values: Incomplete | None = None, kind: Incomplete | None = None, typ: Incomplete | None = None, cname: str | None = None, axis: Incomplete | None = None, pos: Incomplete | None = None, freq: Incomplete | None = None, tz: Incomplete | None = None, index_name: Incomplete | None = None, ordered: Incomplete | None = None, table: Incomplete | None = None, meta: Incomplete | None = None, metadata: Incomplete | None = None) -> None: ...
    @property
    def itemsize(self) -> int: ...
    @property
    def kind_attr(self) -> str: ...
    def set_pos(self, pos: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __ne__(self, other) -> bool: ...
    @property
    def is_indexed(self) -> bool: ...
    def convert(self, values: np.ndarray, nan_rep, encoding: str, errors: str) -> tuple[np.ndarray, np.ndarray] | tuple[Index, Index]: ...
    def take_data(self): ...
    @property
    def attrs(self): ...
    @property
    def description(self): ...
    @property
    def col(self): ...
    @property
    def cvalues(self): ...
    def __iter__(self) -> Iterator: ...
    def maybe_set_size(self, min_itemsize: Incomplete | None = None) -> None: ...
    def validate_names(self) -> None: ...
    def validate_and_set(self, handler: AppendableTable, append: bool) -> None: ...
    def validate_col(self, itemsize: Incomplete | None = None): ...
    def validate_attr(self, append: bool) -> None: ...
    def update_info(self, info) -> None: ...
    def set_info(self, info) -> None: ...
    def set_attr(self) -> None: ...
    def validate_metadata(self, handler: AppendableTable) -> None: ...
    def write_metadata(self, handler: AppendableTable) -> None: ...

class GenericIndexCol(IndexCol):
    @property
    def is_indexed(self) -> bool: ...
    def convert(self, values: np.ndarray, nan_rep, encoding: str, errors: str) -> tuple[Index, Index]: ...
    def set_attr(self) -> None: ...

class DataCol(IndexCol):
    is_an_indexable: bool
    is_data_indexable: bool
    dtype: Incomplete
    data: Incomplete
    def __init__(self, name: str, values: Incomplete | None = None, kind: Incomplete | None = None, typ: Incomplete | None = None, cname: str | None = None, pos: Incomplete | None = None, tz: Incomplete | None = None, ordered: Incomplete | None = None, table: Incomplete | None = None, meta: Incomplete | None = None, metadata: Incomplete | None = None, dtype: DtypeArg | None = None, data: Incomplete | None = None) -> None: ...
    @property
    def dtype_attr(self) -> str: ...
    @property
    def meta_attr(self) -> str: ...
    def __eq__(self, other: object) -> bool: ...
    kind: Incomplete
    def set_data(self, data: ArrayLike) -> None: ...
    def take_data(self): ...
    @classmethod
    def get_atom_string(cls, shape, itemsize): ...
    @classmethod
    def get_atom_coltype(cls, kind: str) -> type[Col]: ...
    @classmethod
    def get_atom_data(cls, shape, kind: str) -> Col: ...
    @classmethod
    def get_atom_datetime64(cls, shape): ...
    @classmethod
    def get_atom_timedelta64(cls, shape): ...
    @property
    def shape(self): ...
    @property
    def cvalues(self): ...
    def validate_attr(self, append) -> None: ...
    def convert(self, values: np.ndarray, nan_rep, encoding: str, errors: str): ...
    def set_attr(self) -> None: ...

class DataIndexableCol(DataCol):
    is_data_indexable: bool
    def validate_names(self) -> None: ...
    @classmethod
    def get_atom_string(cls, shape, itemsize): ...
    @classmethod
    def get_atom_data(cls, shape, kind: str) -> Col: ...
    @classmethod
    def get_atom_datetime64(cls, shape): ...
    @classmethod
    def get_atom_timedelta64(cls, shape): ...

class GenericDataIndexableCol(DataIndexableCol): ...

class Fixed:
    pandas_kind: str
    format_type: str
    obj_type: type[DataFrame | Series]
    ndim: int
    parent: HDFStore
    is_table: bool
    group: Incomplete
    encoding: Incomplete
    errors: Incomplete
    def __init__(self, parent: HDFStore, group: Node, encoding: str | None = 'UTF-8', errors: str = 'strict') -> None: ...
    @property
    def is_old_version(self) -> bool: ...
    @property
    def version(self) -> tuple[int, int, int]: ...
    @property
    def pandas_type(self): ...
    def set_object_info(self) -> None: ...
    def copy(self) -> Fixed: ...
    @property
    def shape(self): ...
    @property
    def pathname(self): ...
    @property
    def attrs(self): ...
    def set_attrs(self) -> None: ...
    def get_attrs(self) -> None: ...
    @property
    def storable(self): ...
    @property
    def is_exists(self) -> bool: ...
    @property
    def nrows(self): ...
    def validate(self, other) -> Literal[True] | None: ...
    def validate_version(self, where: Incomplete | None = None) -> None: ...
    def infer_axes(self) -> bool: ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...
    def write(self, obj, **kwargs) -> None: ...
    def delete(self, where: Incomplete | None = None, start: int | None = None, stop: int | None = None) -> None: ...

class GenericFixed(Fixed):
    attributes: list[str]
    def validate_read(self, columns, where) -> None: ...
    @property
    def is_exists(self) -> bool: ...
    def set_attrs(self) -> None: ...
    encoding: Incomplete
    errors: Incomplete
    def get_attrs(self) -> None: ...
    def write(self, obj, **kwargs) -> None: ...
    def read_array(self, key: str, start: int | None = None, stop: int | None = None): ...
    def read_index(self, key: str, start: int | None = None, stop: int | None = None) -> Index: ...
    def write_index(self, key: str, index: Index) -> None: ...
    def write_multi_index(self, key: str, index: MultiIndex) -> None: ...
    def read_multi_index(self, key: str, start: int | None = None, stop: int | None = None) -> MultiIndex: ...
    def read_index_node(self, node: Node, start: int | None = None, stop: int | None = None) -> Index: ...
    def write_array_empty(self, key: str, value: ArrayLike) -> None: ...
    def write_array(self, key: str, obj: AnyArrayLike, items: Index | None = None) -> None: ...

class SeriesFixed(GenericFixed):
    pandas_kind: str
    attributes: Incomplete
    name: Hashable
    @property
    def shape(self): ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None) -> Series: ...
    def write(self, obj, **kwargs) -> None: ...

class BlockManagerFixed(GenericFixed):
    attributes: Incomplete
    nblocks: int
    @property
    def shape(self) -> Shape | None: ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None) -> DataFrame: ...
    def write(self, obj, **kwargs) -> None: ...

class FrameFixed(BlockManagerFixed):
    pandas_kind: str
    obj_type = DataFrame

class Table(Fixed):
    pandas_kind: str
    format_type: str
    table_type: str
    levels: int | list[Hashable]
    is_table: bool
    metadata: list
    index_axes: Incomplete
    non_index_axes: Incomplete
    values_axes: Incomplete
    data_columns: Incomplete
    info: Incomplete
    nan_rep: Incomplete
    def __init__(self, parent: HDFStore, group: Node, encoding: str | None = None, errors: str = 'strict', index_axes: list[IndexCol] | None = None, non_index_axes: list[tuple[AxisInt, Any]] | None = None, values_axes: list[DataCol] | None = None, data_columns: list | None = None, info: dict | None = None, nan_rep: Incomplete | None = None) -> None: ...
    @property
    def table_type_short(self) -> str: ...
    def __getitem__(self, c: str): ...
    def validate(self, other) -> None: ...
    @property
    def is_multi_index(self) -> bool: ...
    def validate_multiindex(self, obj: DataFrame | Series) -> tuple[DataFrame, list[Hashable]]: ...
    @property
    def nrows_expected(self) -> int: ...
    @property
    def is_exists(self) -> bool: ...
    @property
    def storable(self): ...
    @property
    def table(self): ...
    @property
    def dtype(self): ...
    @property
    def description(self): ...
    @property
    def axes(self) -> itertools.chain[IndexCol]: ...
    @property
    def ncols(self) -> int: ...
    @property
    def is_transposed(self) -> bool: ...
    @property
    def data_orientation(self) -> tuple[int, ...]: ...
    def queryables(self) -> dict[str, Any]: ...
    def index_cols(self): ...
    def values_cols(self) -> list[str]: ...
    def write_metadata(self, key: str, values: np.ndarray) -> None: ...
    def read_metadata(self, key: str): ...
    def set_attrs(self) -> None: ...
    encoding: Incomplete
    errors: Incomplete
    def get_attrs(self) -> None: ...
    def validate_version(self, where: Incomplete | None = None) -> None: ...
    def validate_min_itemsize(self, min_itemsize) -> None: ...
    def indexables(self): ...
    def create_index(self, columns: Incomplete | None = None, optlevel: Incomplete | None = None, kind: str | None = None) -> None: ...
    @classmethod
    def get_object(cls, obj, transposed: bool): ...
    def validate_data_columns(self, data_columns, min_itemsize, non_index_axes): ...
    def process_axes(self, obj, selection: Selection, columns: Incomplete | None = None) -> DataFrame: ...
    def create_description(self, complib, complevel: int | None, fletcher32: bool, expectedrows: int | None) -> dict[str, Any]: ...
    def read_coordinates(self, where: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...
    def read_column(self, column: str, where: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...

class WORMTable(Table):
    table_type: str
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...
    def write(self, obj, **kwargs) -> None: ...

class AppendableTable(Table):
    table_type: str
    def write(self, obj, axes: Incomplete | None = None, append: bool = False, complib: Incomplete | None = None, complevel: Incomplete | None = None, fletcher32: Incomplete | None = None, min_itemsize: Incomplete | None = None, chunksize: int | None = None, expectedrows: Incomplete | None = None, dropna: bool = False, nan_rep: Incomplete | None = None, data_columns: Incomplete | None = None, track_times: bool = True) -> None: ...
    def write_data(self, chunksize: int | None, dropna: bool = False) -> None: ...
    def write_data_chunk(self, rows: np.ndarray, indexes: list[np.ndarray], mask: npt.NDArray[np.bool_] | None, values: list[np.ndarray]) -> None: ...
    def delete(self, where: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...

class AppendableFrameTable(AppendableTable):
    pandas_kind: str
    table_type: str
    ndim: int
    obj_type: type[DataFrame | Series]
    @property
    def is_transposed(self) -> bool: ...
    @classmethod
    def get_object(cls, obj, transposed: bool): ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...

class AppendableSeriesTable(AppendableFrameTable):
    pandas_kind: str
    table_type: str
    ndim: int
    obj_type = Series
    @property
    def is_transposed(self) -> bool: ...
    @classmethod
    def get_object(cls, obj, transposed: bool): ...
    def write(self, obj, data_columns: Incomplete | None = None, **kwargs) -> None: ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None) -> Series: ...

class AppendableMultiSeriesTable(AppendableSeriesTable):
    pandas_kind: str
    table_type: str
    def write(self, obj, **kwargs) -> None: ...

class GenericTable(AppendableFrameTable):
    pandas_kind: str
    table_type: str
    ndim: int
    obj_type = DataFrame
    levels: list[Hashable]
    @property
    def pandas_type(self) -> str: ...
    @property
    def storable(self): ...
    non_index_axes: Incomplete
    nan_rep: Incomplete
    index_axes: Incomplete
    values_axes: Incomplete
    data_columns: Incomplete
    def get_attrs(self) -> None: ...
    def indexables(self): ...
    def write(self, **kwargs) -> None: ...

class AppendableMultiFrameTable(AppendableFrameTable):
    table_type: str
    obj_type = DataFrame
    ndim: int
    @property
    def table_type_short(self) -> str: ...
    def write(self, obj, data_columns: Incomplete | None = None, **kwargs) -> None: ...
    def read(self, where: Incomplete | None = None, columns: Incomplete | None = None, start: int | None = None, stop: int | None = None): ...

class Selection:
    table: Incomplete
    where: Incomplete
    start: Incomplete
    stop: Incomplete
    condition: Incomplete
    filter: Incomplete
    terms: Incomplete
    coordinates: Incomplete
    def __init__(self, table: Table, where: Incomplete | None = None, start: int | None = None, stop: int | None = None) -> None: ...
    def generate(self, where): ...
    def select(self): ...
    def select_coords(self): ...
