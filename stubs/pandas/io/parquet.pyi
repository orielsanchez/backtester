from _typeshed import Incomplete
from pandas import DataFrame as DataFrame, get_option as get_option
from pandas._config import using_pyarrow_string_dtype as using_pyarrow_string_dtype
from pandas._libs import lib as lib
from pandas._typing import DtypeBackend as DtypeBackend, FilePath as FilePath, ReadBuffer as ReadBuffer, StorageOptions as StorageOptions, WriteBuffer as WriteBuffer
from pandas.compat._optional import import_optional_dependency as import_optional_dependency
from pandas.errors import AbstractMethodError as AbstractMethodError
from pandas.io._util import arrow_string_types_mapper as arrow_string_types_mapper
from pandas.io.common import IOHandles as IOHandles, get_handle as get_handle, is_fsspec_url as is_fsspec_url, is_url as is_url, stringify_path as stringify_path
from pandas.util._decorators import doc as doc
from pandas.util._exceptions import find_stack_level as find_stack_level
from pandas.util._validators import check_dtype_backend as check_dtype_backend
from typing import Any, Literal

def get_engine(engine: str) -> BaseImpl: ...

class BaseImpl:
    @staticmethod
    def validate_dataframe(df: DataFrame) -> None: ...
    def write(self, df: DataFrame, path, compression, **kwargs): ...
    def read(self, path, columns: Incomplete | None = None, **kwargs) -> DataFrame: ...

class PyArrowImpl(BaseImpl):
    api: Incomplete
    def __init__(self) -> None: ...
    def write(self, df: DataFrame, path: FilePath | WriteBuffer[bytes], compression: str | None = 'snappy', index: bool | None = None, storage_options: StorageOptions | None = None, partition_cols: list[str] | None = None, filesystem: Incomplete | None = None, **kwargs) -> None: ...
    def read(self, path, columns: Incomplete | None = None, filters: Incomplete | None = None, use_nullable_dtypes: bool = False, dtype_backend: DtypeBackend | lib.NoDefault = ..., storage_options: StorageOptions | None = None, filesystem: Incomplete | None = None, **kwargs) -> DataFrame: ...

class FastParquetImpl(BaseImpl):
    api: Incomplete
    def __init__(self) -> None: ...
    def write(self, df: DataFrame, path, compression: Literal['snappy', 'gzip', 'brotli'] | None = 'snappy', index: Incomplete | None = None, partition_cols: Incomplete | None = None, storage_options: StorageOptions | None = None, filesystem: Incomplete | None = None, **kwargs) -> None: ...
    def read(self, path, columns: Incomplete | None = None, filters: Incomplete | None = None, storage_options: StorageOptions | None = None, filesystem: Incomplete | None = None, **kwargs) -> DataFrame: ...

def to_parquet(df: DataFrame, path: FilePath | WriteBuffer[bytes] | None = None, engine: str = 'auto', compression: str | None = 'snappy', index: bool | None = None, storage_options: StorageOptions | None = None, partition_cols: list[str] | None = None, filesystem: Any = None, **kwargs) -> bytes | None: ...
def read_parquet(path: FilePath | ReadBuffer[bytes], engine: str = 'auto', columns: list[str] | None = None, storage_options: StorageOptions | None = None, use_nullable_dtypes: bool | lib.NoDefault = ..., dtype_backend: DtypeBackend | lib.NoDefault = ..., filesystem: Any = None, filters: list[tuple] | list[list[tuple]] | None = None, **kwargs) -> DataFrame: ...
